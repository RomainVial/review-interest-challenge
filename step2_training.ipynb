{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import variables\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, linewidth=130)\n",
    "\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = (\"device=cpu,floatX=float32,gpuarray.preallocate=1\")\n",
    "\n",
    "from keras.callbacks import Callback, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from models import cbow, lstm, bilstm, attention_lstm\n",
    "from models import save_model_without_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_embeddings(embeddingfn):\n",
    "    return np.load(embeddingfn)\n",
    "\n",
    "embeddingfn = 'cache/embedding_weights.npy'\n",
    "embedding_weights = read_embeddings(embeddingfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'train':{}, 'val':{}, 'test':{}}\n",
    "\n",
    "# Loading data from the training set\n",
    "X_text_vec = np.load('cache/train/text_vec.npy')\n",
    "X_text_ids = np.load('cache/train/text_ids.npy')\n",
    "X_titl_vec = np.load('cache/train/titl_vec.npy')\n",
    "X_titl_ids = np.load('cache/train/titl_ids.npy')\n",
    "X_ratg = np.load('cache/train/ratg.npy')\n",
    "y = np.load('cache/train/labels.npy')\n",
    "\n",
    "# Creating train and val splits\n",
    "val_split = variables.VALIDATION_SPLIT\n",
    "size = X_text_vec.shape[0]\n",
    "\n",
    "seed = 821  # np.random.randint(1234)\n",
    "print 'Seed {}'.format(seed)\n",
    "\n",
    "nb_training_samples = int((1.-val_split)*size)\n",
    "np.random.seed(seed)\n",
    "train_set = np.random.choice(np.arange(size),size=nb_training_samples, replace=False)\n",
    "val_set = np.delete(np.arange(size),train_set)\n",
    "\n",
    "# Adding splits to the dictionary\n",
    "data['train']['text_vec'] = X_text_vec[train_set,:]\n",
    "data['train']['text_ids'] = X_text_ids[train_set,:]\n",
    "data['train']['titl_vec'] = X_titl_vec[train_set,:]\n",
    "data['train']['titl_ids'] = X_titl_ids[train_set,:]\n",
    "data['train']['ratg'] = X_ratg[train_set,:]\n",
    "data['train']['y'] = y[train_set,:]\n",
    "\n",
    "data['val']['text_vec'] = X_text_vec[val_set,:]\n",
    "data['val']['text_ids'] = X_text_ids[val_set,:]\n",
    "data['val']['titl_vec'] = X_titl_vec[val_set,:]\n",
    "data['val']['titl_ids'] = X_titl_ids[val_set,:]\n",
    "data['val']['ratg'] = X_ratg[val_set,:]\n",
    "data['val']['y'] = y[val_set,:]\n",
    "\n",
    "data['test']['text_vec'] = np.load('cache/test/text_vec.npy')\n",
    "data['test']['text_ids'] = np.load('cache/test/text_ids.npy')\n",
    "data['test']['titl_vec'] = np.load('cache/test/titl_vec.npy')\n",
    "data['test']['titl_ids'] = np.load('cache/test/titl_ids.npy')\n",
    "data['test']['ratg'] = np.load('cache/test/ratg.npy')\n",
    "\n",
    "print 'Train:', data['train']['text_vec'].shape\n",
    "print 'Val:', data['val']['text_vec'].shape\n",
    "print 'Val:', data['test']['text_vec'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AUC(Callback):\n",
    "    def __init__(self, data_val):\n",
    "        super(Callback, self).__init__()\n",
    "        self.data = data_val[0]\n",
    "        self.labl = data_val[1]\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(self.data, verbose=0)\n",
    "        score = roc_auc_score(self.labl, y_pred)\n",
    "        print ' - val_auc - {:.4f}'.format(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, data_train, data_val):\n",
    "    nb_epochs = 100\n",
    "    batch_size = 128\n",
    "    is_earlyStopping = True\n",
    "    \n",
    "    # Compile model\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, clipnorm=1.)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    # Callbacks\n",
    "    auc = AUC(data_val)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='auto', epsilon=0.0015)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "    \n",
    "    callbacks = [reduce_lr, auc]\n",
    "    if is_earlyStopping:\n",
    "        callbacks += [early_stopping]\n",
    "        \n",
    "    # Train model\n",
    "    try:\n",
    "        model.fit(data_train[0], data_train[1],\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=nb_epochs,\n",
    "                  validation_data=(data_val[0], data_val[1]),\n",
    "                  callbacks=callbacks,\n",
    "                  verbose=True)\n",
    "    except KeyboardInterrupt:\n",
    "        print '\\nTraining interrupted by user.'\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model, data_train, data_val, data_test = cbow(data, embedding_weights, verbose=True)\n",
    "#model, data_train, data_val, data_test = lstm(data, embedding_weights, verbose=True)\n",
    "#model, data_train, data_val, data_test = bilstm(data, embedding_weights, verbose=True)\n",
    "model, data_train, data_val, data_test = attention_lstm(data, embedding_weights, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = train(model, data_train, data_val)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.load_weights('models/lstm_CTR_64.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(data_val[0], batch_size=128, verbose=True)\n",
    "val_auc = roc_auc_score(data_val[1], pred)\n",
    "print \"\\nValidation AUC: {}\".format(val_auc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_model_without_embedding(model, 'models/bilstm_CTR_32.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict(data_test, batch_size=128, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output/output.csv', 'wb') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=';')\n",
    "    csvwriter.writerow(['ID', 'Target'])\n",
    "    for i in range(test_pred.size):\n",
    "        if np.amax(data['test']['text_vec'][i,:]) == 0:\n",
    "            # If there are no embeddings for the review, it probably\n",
    "            # means that the orignial message is not informative\n",
    "            csvwriter.writerow([i+80000, 0.])\n",
    "        else:\n",
    "            csvwriter.writerow([i+80000, test_pred[i,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble of already trained models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "archs = [cbow, lstm, bilstm]\n",
    "weights = ['models/cbow_512.h5', 'models/lstm_CTR_64.h5', 'models/bilstm_CTR_32.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for idx,arch in enumerate(archs):\n",
    "    model, _, data_val, _ = arch(data, embedding_weights, verbose=False)\n",
    "    model.load_weights(weights[idx], by_name=True)\n",
    "    preds.append(model.predict(data_val[0], batch_size=128, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_ensemble(preds):\n",
    "    samples = 1000\n",
    "    grid = np.random.uniform(size=(samples,len(preds)))\n",
    "    grid = grid / np.sum(grid, axis=1)[:,np.newaxis]\n",
    "    \n",
    "    results = np.zeros((samples,))\n",
    "    \n",
    "    for i in range(samples):\n",
    "        ensemble = np.zeros(preds[0].shape)\n",
    "        for k in range(len(preds)):\n",
    "            ensemble += grid[i,k] * preds[k]\n",
    "        results[i] = roc_auc_score(data['val']['y'], ensemble)\n",
    "    print 'Best ensemble AUC: {:.6f} with weights'.format(np.amax(results)), grid[np.argmax(results),:]\n",
    "    return grid[np.argmax(results),:]\n",
    "\n",
    "ensemble_weights = find_best_ensemble(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "for idx,arch in enumerate(archs):\n",
    "    model, _, _, data_test = arch(data, embedding_weights, verbose=False)\n",
    "    model.load_weights(weights[idx], by_name=True)\n",
    "    test_preds.append(model.predict(data_test, batch_size=128, verbose=True))\n",
    "\n",
    "test_ensemble = np.zeros(test_preds[0].shape)\n",
    "for k in range(len(preds)):\n",
    "    test_ensemble += ensemble_weights[k] * test_preds[k]\n",
    "\n",
    "with open('output/ensemble_output.csv', 'wb') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=';')\n",
    "    csvwriter.writerow(['ID', 'Target'])\n",
    "    for i in range(test_ensemble.size):\n",
    "        if np.amax(data['test']['text_vec'][i,:]) == 0:\n",
    "            # If there are no embeddings for the review, it probably\n",
    "            # means that the orignial message is not informative\n",
    "            csvwriter.writerow([i+80000, 0.])\n",
    "        else:\n",
    "            csvwriter.writerow([i+80000, test_ensemble[i,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
